# Voice-First AI Assistant (Local, Privacy-Preserving)

An applied AI system demonstrating **speech recognition, LLM-based reasoning, safety guardrails, and modular AI architecture**.


## ğŸ” What This Project Demonstrates
- End-to-end AI system design
- Voice-based humanâ€“AI interaction
- LLM integration (Groq)
- Safety-aware intent classification
- Local-first, privacy-preserving architecture
- Modular, extensible Python codebase


## ğŸ“Œ Overview
A local, privacy-first, voice-driven AI assistant designed for daily personal use.

Unlike cloud-based assistants, this system runs locally, activates only on explicit user input, and enforces strict safety and memory controls.

---

## âœ¨ Key Features
- LLM-based reasoning using Groq
- Push-to-talk voice interaction (no always-on listening)
- Explicit, user-controlled long-term memory
- Intent classification with safety guardrails
- Sandboxed task execution
- Modular and extensible architecture

---


## ğŸ—ï¸ System Architecture
Voice Input  
â†’ Speech-to-Text (Whisper)  
â†’ Mode & Intent Detection  
â†’ Safety Gate  
â†’ LLM Reasoning (Groq) or Tool Execution  
â†’ Text-to-Speech Response

---

This layered design ensures **clear separation of concerns**, predictable behavior, and strong safety boundaries.

---

## ğŸ” Privacy & Safety Principles

This assistant is designed to be **trustworthy by default**.

- No always-on microphone
- No silent memory storage
- No OS-level or shell command execution
- No user data stored remotely
- All personal data remains local to the machine
- LLM access is used strictly for reasoning and language generation

---

## ğŸ¯ Intended Role Fit
This project is aligned with:
- AI/ML Engineer (Applied Systems)
- AI Engineer â€“ Voice / Conversational AI
- Software Engineer (AI-integrated systems)

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
2. Create a virtual environment
python -m venv venv
venv\Scripts\activate
3. Install dependencies
pip install -r requirements.txt
4. Configure environment variables
Create a .env file in the project root:

GROQ_API_KEY=your_api_key_here
Note: API keys and personal data are never committed to the repository.

5. Run the assistant
python src/main.py
Press Ctrl + Alt + Space to speak

Press ESC to exit

ğŸ§  Why This Project Exists
This assistant was built to reduce friction in daily thinking and productivity by providing a private, voice-first interface to intelligence, instead of repeatedly opening web-based chat applications.

The goal is not autonomy.
The goal is useful presence with human control.

ğŸ“Œ Notes
This project is intended primarily for personal use

Users must supply their own API keys

Personal memory and notes are stored locally and never shared

Future improvements are guided by real usage, not feature bloat

ğŸ”® Future Work (Optional)

Performance tuning

Config-driven behavior

Optional open-source framework version (without personal data)


ğŸ“ Project Structure

voice_ai_agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py            # Application entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/             # Speech-to-text (Whisper)
â”‚   â”œâ”€â”€ brain/             # LLM reasoning logic
â”‚   â”œâ”€â”€ safety/            # Intent classification & guardrails
â”‚   â”œâ”€â”€ tools/             # Sandboxed task execution
â”‚   â”œâ”€â”€ memory/            # Explicit, user-controlled memory
â”‚   â”œâ”€â”€ modes/             # Interaction modes (normal, briefing)
â”‚   â””â”€â”€ voice/             # Text-to-speech
â”‚
â”œâ”€â”€ user_data/             # Local-only personal data (gitignored)
â”œâ”€â”€ config.yaml            # Runtime configuration
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš ï¸ Disclaimer

This project is provided for personal and educational use.
No guarantees are made regarding fitness for production or commercial deployment.

ğŸ™ï¸ Privacy-First Voice AI Assistant

A local, privacy-first voice assistant designed for daily personal use â€” not for surveillance, automation hype, or cloud dependency.

This project emphasizes engineering discipline: safety, intent control, explicit memory, and reliability â€” instead of flashy demos.

ğŸ§  Why This Project Exists

Most modern voice assistants are:

Always listening

Cloud-dependent

Opaque about data usage

Difficult to reason about safely

This assistant was built with the opposite philosophy:

Push-to-talk only (no background listening)

Local execution wherever possible

Explicit intent and safety gates

User-controlled memory

No silent automation

The goal is not to replace tools, but to support focused thinking and daily planning.

âœ¨ Core Capabilities
ğŸ™ Voice Interaction

Push-to-talk activation via keyboard hotkey

No always-on microphone

Low-latency speech-to-text (Whisper)

ğŸ§  Reasoning Layer

Natural language understanding via LLM (Groq)

Deterministic intent classification

Calm, concise responses by default

ğŸ›¡ Safety & Intent Control

Every request is classified before action:

QUERY â€” informational requests

TASK â€” limited, sandboxed actions

SYSTEM_ACTION â€” blocked

REJECT â€” blocked

The LLM never executes actions directly.

ğŸ›  Safe Tool Execution

Explicitly registered tools only

Sandboxed file access

No shell commands

No OS-level actions

Current tools:

Save personal notes

Read saved notes

ğŸ§  Memory (Explicit & Ethical)

No silent data collection

Memory written only on explicit user request

Local persistence (JSON)

Fully user-auditable and removable

Memory types:

Long-term factual memory (explicit)

Session context (temporary)

No background profiling. Ever.

ğŸ“… Daily Briefing / Focus Mode

A calm, proactive mode that:

Summarizes saved context

Suggests one focus for the next hour

Asks one clarifying question

No notifications.
No nagging.
Triggered only when requested.

ğŸ—ï¸ Architecture Overview

The assistant follows a deterministic, layered processing pipeline:

ğŸ—ï¸ Architecture Overview

The assistant follows a deterministic, layered processing pipeline:

Voice Input
â†’ Speech-to-Text (Whisper)
â†’ Mode & Intent Detection
â†’ Safety Gate
â†’ LLM Reasoning or Tool Execution
â†’ Text-to-Speech Response


Each layer has a single responsibility, making the system predictable, safe, and easy to extend.

ğŸ§© Design Principles

Single, explicit entry point

Clear separation of concerns

Deterministic control flow

No hidden or implicit state

User control over memory and actions

ğŸ“ Project Structure 

voice_ai_agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py            # Application entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/             # Speech-to-text (Whisper)
â”‚   â”œâ”€â”€ brain/             # LLM reasoning logic
â”‚   â”œâ”€â”€ safety/            # Intent classification & guardrails
â”‚   â”œâ”€â”€ tools/             # Sandboxed task execution
â”‚   â”œâ”€â”€ memory/            # Explicit, user-controlled memory
â”‚   â”œâ”€â”€ modes/             # Interaction modes (normal, briefing)
â”‚   â””â”€â”€ voice/             # Text-to-speech
â”‚
â”œâ”€â”€ user_data/             # Local-only personal data (gitignored)
â”œâ”€â”€ config.yaml            # Runtime configuration
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


This structure is:

scalable

readable

recruiter-friendly

immediately understandable

ğŸ” Privacy & Ethics

This assistant:

Does not listen unless explicitly activated

Does not transmit audio recordings

Does not store data without consent

Runs entirely on the userâ€™s machine

Keeps API keys local and uncommitted

Privacy is a default, not an option.

ğŸš€ Getting Started
1. Clone the repository
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>

2. Create a virtual environment
python -m venv venv
venv\Scripts\activate

3. Install dependencies
pip install -r requirements.txt

4. Configure environment variables

Create a .env file in the project root:

GROQ_API_KEY=your_api_key_here


API keys and personal data are never committed to the repository.

5. Run the assistant
python src/main.py


Press Ctrl + Alt + Space to speak

Press ESC to exit

ğŸ“Œ Project Status

Personal, private assistant

Actively used and iterated

Not published as a product

Not intended for mass deployment

This is a deliberately scoped personal system, not a startup demo.

ğŸ”® Future Work (Optional)

Performance tuning

Config-driven behavior

Optional open-source framework version (without personal data)

âš ï¸ Disclaimer

This project is provided for personal and educational use.
No guarantees are made regarding fitness for production or commercial deployment.

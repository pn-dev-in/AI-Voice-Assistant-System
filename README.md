# ğŸ™ï¸ Personal Voice-First AI Assistant

A **local, privacy-first, voice-driven AI assistant** designed for personal daily use.

This project focuses on **usability, safety, and human control**, rather than automation hype or always-on surveillance.

Unlike cloud-based chatbots, this assistant acts as a **personal AI mediator** that runs locally and responds only when explicitly invoked.

---

## âœ¨ Key Features

- ğŸ¤ **Push-to-talk voice interaction** (no always-on listening)
- ğŸ§  **LLM-based reasoning** powered by Groq
- ğŸ”Š **Voice responses** via Text-to-Speech
- ğŸ§­ **Intent classification & safety guardrails**
- ğŸ—‚ï¸ **Explicit long-term memory** (user-controlled, opt-in only)
- ğŸ› ï¸ **Sandboxed task execution** (notes, simple utilities)
- ğŸ§© **Modular and extensible architecture**

---

## ğŸ—ï¸ Architecture Overview

Voice Input
â†“
Speech-to-Text (Whisper)
â†“
Intent & Safety Layer
â†“
LLM Reasoning (Groq)
â†“
Tool / Memory / Response
â†“
Text-to-Speech


This layered design ensures **clear separation of concerns**, predictable behavior, and strong safety boundaries.

---

## ğŸ” Privacy & Safety Principles

This assistant is designed to be **trustworthy by default**.

- No always-on microphone
- No silent memory storage
- No OS-level or shell command execution
- No user data stored remotely
- All personal data remains local to the machine
- LLM access is used strictly for reasoning and language generation

---

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
2. Create a virtual environment
python -m venv venv
venv\Scripts\activate
3. Install dependencies
pip install -r requirements.txt
4. Configure environment variables
Create a .env file in the project root:

GROQ_API_KEY=your_api_key_here
Note: API keys and personal data are never committed to the repository.

5. Run the assistant
python src/main.py
Press Ctrl + Alt + Space to speak

Press ESC to exit

ğŸ§  Why This Project Exists
This assistant was built to reduce friction in daily thinking and productivity by providing a private, voice-first interface to intelligence, instead of repeatedly opening web-based chat applications.

The goal is not autonomy.
The goal is useful presence with human control.

ğŸ“Œ Notes
This project is intended primarily for personal use

Users must supply their own API keys

Personal memory and notes are stored locally and never shared

Future improvements are guided by real usage, not feature bloat

ğŸ”® Future Work (Optional)

Performance tuning

Config-driven behavior

Optional open-source framework version (without personal data)

âš ï¸ Disclaimer

This project is provided for personal and educational use.
No guarantees are made regarding fitness for production or commercial deployment.

ğŸ“ Project Structure

voice_ai_agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py            # Application entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/             # Speech-to-text (Whisper)
â”‚   â”œâ”€â”€ brain/             # LLM reasoning logic
â”‚   â”œâ”€â”€ safety/            # Intent classification & guardrails
â”‚   â”œâ”€â”€ tools/             # Sandboxed task execution
â”‚   â”œâ”€â”€ memory/            # Explicit, user-controlled memory
â”‚   â”œâ”€â”€ modes/             # Interaction modes (normal, briefing)
â”‚   â””â”€â”€ voice/             # Text-to-speech
â”‚
â”œâ”€â”€ user_data/             # Local-only personal data (gitignored)
â”œâ”€â”€ config.yaml            # Runtime configuration
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
